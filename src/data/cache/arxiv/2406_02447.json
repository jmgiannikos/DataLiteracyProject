{
  "arxiv_id": "2406.02447",
  "found": true,
  "title": "Federated Class-Incremental Learning with Hierarchical Generative Prototypes",
  "authors": [
    "Riccardo Salami",
    "Pietro Buzzega",
    "Matteo Mosconi",
    "Mattia Verasani",
    "Simone Calderara"
  ],
  "first_author": "Riccardo Salami",
  "summary": "Federated Learning (FL) aims at unburdening the training of deep models by distributing computation across multiple devices (clients) while safeguarding data privacy. On top of that, Federated Continual Learning (FCL) also accounts for data distribution evolving over time, mirroring the dynamic nature of real-world environments. While previous studies have identified Catastrophic Forgetting and Client Drift as primary causes of performance degradation in FCL, we shed light on the importance of Incremental Bias and Federated Bias, which cause models to prioritize classes that are recently introduced or locally predominant, respectively. Our proposal constrains both biases in the last layer by efficiently finetuning a pre-trained backbone using learnable prompts, resulting in clients that produce less biased representations and more biased classifiers. Therefore, instead of solely relying on parameter aggregation, we leverage generative prototypes to effectively balance the predictions of the global model. Our method significantly improves the current State Of The Art, providing an average increase of +7.8% in accuracy.",
  "primary_category": "cs.LG",
  "categories": [
    "cs.LG"
  ],
  "published": "2024-06-04T16:12:27+00:00",
  "updated": "2025-05-24T09:52:52+00:00",
  "doi": null,
  "journal_ref": null,
  "comment": null,
  "pdf_url": "https://arxiv.org/pdf/2406.02447v4",
  "entry_id": "http://arxiv.org/abs/2406.02447v4"
}