.
et al.
m
þ
&
a&a
a&a ann. rev.
a&as
apj
apjl
apss
nature
science
mnras
/bdocument/
this paper serves as an introduction to the current book. it provides
the basic notions of long-baseline optical/infrared interferometry prior
to reading all the subsequent chapters, and is not an extended
introduction to the field.
interferometry concepts
    f. millour[laboratoire lagrange, umr7293, université de nice sophia-antipolis, cnrs, observatoire de la côte d'azur, bd. de l'observatoire, 06304 nice, france. email: ]
    eas publication series, vol. 69, 2014
============================================================================================================================================================================
§ introduction
long-baseline interferometry in the optical and infrared wavelengths
is living a “golden age” which indicates its maturity as an observing
technique. i chose here not to develop the history of interferometry
as it has already been extensively presented in numerous reviews
(e.g. shao & colavita ,
lawson , jankov , and including in
this book: léna ).
i would also suggest reading the excellent book on optical
interferometry from a. glindemann (), where
all the notions which are rapidly explained here, are detailed.
i will rather try to get into more details of new ideas and
now-commonly understood aspects which have been developed in the years
after the publication of millour (), namely
the breakthrough of spectrally-dispersed interferometry and its
consequences, how to cope with chromatic datasets, how to make a model
of such data, and imaging techniques. i will also try to present what
makes a good interferometer.
§ why high-angular resolution?
the resolution power of an optical system, given its optical elements
are perfect, is only related to its size (diameter). this property was
noted by lord rayleigh, which gave his name to the so-called empiric
rayleigh criterion :
with  the telescope diameter, and  the wavelength of
observation. this relation comes from an approximate estimate of the
radius of the first zero in the airy function, which is involved in
the description of the diffraction pattern of a round pupil (see
later).
the consequence is that, even making abstraction of all practical
problems affecting an instrument, there is a fundamental limit in its
resolution power, directly linked to its diameter and the
wave-properties of light. if one takes the simple example of our sun,
which has an approximate diameter of 30”, an instrument with a pupil
smaller than m will not be able to resolve it in the
visible (i.e. at  nm, see
defrère  ). as an illustration of this
effect, most insects, whose eyes are composed of tiny ommatidia
(m) see the sun as a point source, whereas men, whose pupil
is  mm, can resolve it (with the use of an adequate
filter, of course). to resolve one of the biggest star in the sky,
betelgeuse with a diameter of 44 mas (michelson &
pease, , haubois  ),
the needed telescope diameter would be  m, i.e. slightly
larger than the 100 inches (2.5 m) of the hooker telescope used by
michelson & pease () to resolve it (hence
the installation of a boom supporting mirrors to enlarge the available
aperture). to resolve a dwarf star similar to the sun located at
10 pc (i.e. a star with an angular diameter of 0.9 milli-arcsecond),
one would need to build a 150 m diameter telescope, which is simply
unfeasible with the current techniques (see e.g. monnet &
gilmozzi, ).
the way to go to get finer details on stars is interferometry,
i.e. combining several telescopes into a “virtual telescope” the
diameter of the utmost-separated apertures.
§ psf and  plane
to understand what an interferometer does, one needs to understand what
a point spread function (psf) is. i recall here the introduction of
millour ().
§.§ single-aperture psf and u-v patch
the light propagating from the astrophysical source to the observer
has come a long way. let us represent it by the classical
electromagnetic wave:
e⃗(z⃗,t)     =    e⃗_⃗0⃗(z⃗) ^ω t
    b⃗(z⃗,t)     =    b⃗_⃗0⃗(z⃗) ^ω t
here,  represents the electric field,  the magnetic
field, which form a plane perpendicular to the propagation direction,
 is the position in space,  is the time and  the
light pulsation, related to the wavelength  and the speed of
light  by .
notations used in this paper. the light propagates from the
    sky to the detector through the instrument pupil. each plane of
    interest has its own coordinate system.
  
the light intensity at the focus of the instrument (see
fig.  for details) is the result of the
superposition of many electromagnetic waves coming from the pupil of
the instrument:
i(x⃗)     =    < e⃗(x⃗,t) ^2 >_t
        =    < ∑_i e⃗(p⃗_⃗i⃗,t - τ_i)
      ^2 >_t
the  index represent a number of arbitrarily chosen points in the
plane of interest.  is the 2d coordinate vector onto the
focal plane, screen or detector. for example,  is the
coordinate vector onto the pupil plane.  represents the
propagation delay between the different incoming electromagnetic
waves.
when the pupil is split like in fig. , it is
convenient to define  the separation vector between the
sub-pupils. this vector, or its length, is often called “baseline”.
if one considers a point-source light emitter (i.e. the wavefront at the
entrance pupil is a plane), this expression can be integrated onto the
pupil, instead of summed as in eq.  to see what the
shape of the intensity in the image plane is.
for example, in the case of a round pupil of diameter , the light
intensity will follow an airy pattern (see the demonstration
  in perez  page 288), which writes:
i(ρ)     =    (π d^2/4)^2 [2
        j_1(πρ d)/πρ d]^2
with  and  the 1 order bessel
function. an illustration of different pupils and the associated psf
is shown in figure . the consequence is that a
point-source does not appear as a point source through a telescope or
instrument, owing to the rayleigh criterion (the factor 1.22 comes
from the first zero of the bessel function). an instrument is
therefore limited in angular resolution by the diameter (or maximum
baseline) of its aperture.
top, from left to right: simulated apertures for
    different instruments with similar angular resolution ; round
    pupil ; vlt pupil ; keck pupil ; 3 telescopes interferometer ; 2
    telescopes interferometer. bottom, from left to right: the
    corresponding psf 
  
§.§ diluted or masked-aperture psf and u-v plane
an interferometer, or a pupil-masking instrument, is a set of multiple
telescopes (or apertures ) which are combined together to form
interference patterns on a given common source, represented by its
sky-brightness distribution . for
convenience, one will always considers that the pupils are infinitely
small, and they are identified by their indices  or .
the interferometer is sensitive to the incoming light coherence,
measured by the mutual coherence function. this function is defined as
the correlation between two incident wavefronts  coming from
positions  and . the two beams of light from
each positions have a delay :
the light intensity can then be developed as a function of 
from eq :
one can note here that the terms  are just the light
intensity , as if there was only one unperturbed source
of light. the delays  are set as a function of the origin of
the two wavefronts, and of the configuration of the instrument (used
optics, focal length, etc.) and, in the focal plane of the instrument,
both depend only on the coordinates in that plane. let us pose . when dealing with 2 wavefronts, just like in an
interferometer, the equation  simplifies in:
i(x⃗)     =     i_1(x⃗) + i_2(x⃗) +
      γ_1,2(τ) + γ_1,2^*(τ)
if one normalises the term  by the total flux, this
defines the complex coherence degree :
when considering a 1d-interferogram with abscissa  (for example
when one axis is anamorphosed in order to feed it into a
spectrograph), equation  becomes:
i(x)     =    [ i_1(x) + i_2(x) ] [ 1 + (
        γ_1,2(τ) ) ]
        =    [ i_1(x) + i_2(x)
        ] [ 1 + μ^ obj_1,2cos( 2 π x/λ + ϕ^ obj_1,2) ]
being the modulus of  and  its phase
(). the cosine modulation
corresponds to the intensity fringes that an optical interferometer
measures. eq.  and its variants is often
referred as “the interferometric equation”, and describes the
intensity interference pattern (or interferogram) as seen on a screen
or detector.  and  are often called the
visibility or contrast, and phase of the
interferogram, respectively. an illustration of this equation can be
seen in figure , left. the  variable is a length
corresponding to the delay difference between the two recombined
beams. it can be directly projected on the detector, as is done in a
multiaxial instrument, or a time-modulated variation of  can be introduced as is often done in a
coaxial instrument (see e.g. berger  , or the paper in this book: berger  for more
  details).
this equation, with minor modifications (due to the flux envelope of
the slits) also drives the well-known young's two-slit experiment.
§ light source and light coherence
with the young's experiment, a simple test to do is to change the
physical size of the source by e.g. putting a varying-size diaphragm
in front of it. when the source's size changes, one can observe that
the fringe contrast also changes, and there are specific sizes at
which the fringes completely wash out. we saw in the previous sections
the intensity function of an interferometer in the case of a point
source. here i will detail a little what happens when the source is
resolved by the instrument or interferometer.
this is where the zernicke and van cittert (zvc) theorem comes into
light, linking the value of  to the object's shape projected onto the plane of
sky:
for a non-coherent and almost monochromatic extended source, the
  complex visibility is the normalised fourier transform (hereafter
  ft) of the brightness distribution of the source.
or written in a mathematical way:
γ_1,2(0)     =    ∬_-∞^∞ s(α,δ) ^-2iπ (uα +
          vδ) d α  d δ/∬_-∞^∞ s(α,δ)  d α  d δ
        =    ft(s)/s^ tot
with here  is the brightness distribution of the
source at angular coordinates  and ,  and  are
the spatial frequencies at which the fourier transform is
computed. the demonstration of this theorem can e.g. be found in
born & wolf (). and here is why
fourier-transforms are so important to interferometry!
3cobject
point source     small     large 
3cimage
1cminterferometer         
    
    
    
    
    
    
    
    
    
    
 
1cmfull pupil        
    
    
    
    
    
    
    
    
    
    
 
top, from left to right: simulated round objects of
    different diameters. middle-left: reproduction of the 2
    telescope interferometer pupil. middle: fringe pattern for
    the different object sizes. note the fringe contrast
    change. bottom-left: reproduction of the ideal round
    pupil. bottom: corresponding image. note the disappearance
    of the airy rings when the object is resolved. 
  
the direct consequence of this theorem is that the fringe contrast and
phase are related to fourier transforms: the larger the object, the
lower will be the contrast (for a “regular” object). an illustration
of this effect is shown in figure .
§.§ coherent flux
as has been seen, the interferometer is sensitive in theory to the
degree of coherence of light , or complex visibility, which is given by the
zernicke and van cittert theorem.
one needs to calculate the visibility values from the interferogram
signal. as this signal has a cosine modulation, one way to extract its
amplitude and phase is to apply a fourier transform and calculate the
power at the modulation frequency  (see
fig. ). the observed ,
noted with “” is:
with . this
equation contains the approximation that the two fluxes 
and  are equal. the case where  and
 are not equal is treated later in this book
(ten brummelaar ).
this method is often called the fourier method, but note that
it has nothing to do with the zvc theorem (eq. ), as it is
just a way to actually measure the visibility.
left: a simulated fringe pattern for a typical multiaxial
  interferometer, with the representation of where the fringe contrast
  and phase can be measured. right: the fourier transform of
  that fringe pattern exhibits two peaks: one at zero frequency,
  representing the total flux, and one at frequency 
  representing the fringe contrast. note that the white noise from the
  data appears as “grass” in the fourier
  transform.  
another way is to measure the amplitude of the fringes in the image
space, for example, one can measure one fringe at 4 different points
 each one separated to each other in phase by  (see
fig. ). the visibility amplitude can be computed this
way:
and the visibility phase:
one needs to note here that the abcd method relies on the knowledge of
the shape of the fringes (a cosine function) and on the fact that the
a,b,c and d samples are exactly offset by . a generalisation of
that method, called p2vm (millour  ,
  tatulli  ), was proposed and implemented on the amber instrument (petrov  ). the basic idea is to
use the a priori information of the fringes shape to adjust a
model to the data in order to obtain the visibilities. the method is
thoroughly described in tatulli  ().
principle of the abcd method: 4 measurements are made onto
    one single fringe, dephased by  each, owing to the fringe
    contrast and phase.
  
to get an overview and understanding of how to reduce data for a
specific instrument, it is always better to read the corresponding
paper. for example mourard  () for the chara/vega instrument, petrov  () for the vlti/amber instrument,
ten brummelaar () for chara/classic,
perrin (, )
for chara/fluor and vlti/vinci, etc.
§.§ the  problem
one very specific problem of optical long-baseline interferometry is
called the “ problem”. it is related to the sparsity of
measurements the interferometers can provide. indeed, contrary to
classical imaging, a two telescopes interferometer measurement samples
only one point in the frequency domain of equation ,
usually noted  plane. more details are given in
millour (), therefore i will just recall the
different ways to fill the  plane:
supersynthesis: the rotation of earth relative to the celestial
     sphere makes the baseline change with time. the  tracks
     are on an arc of ellipse. the exact expression of the 
     tracks is given in segransan () and
     recalled in millour ().
add more telescopes: the number of  points for one measurement
     is equal to the number of baselines, roughly proportionnal to the
     square of the number of telescopes, following the relation
     
make use of wavelength: the spatial frequencies are
  proportionnal to the wave number  and trace
  radial lines in the  plane.
an illustration of these is shown in table  for the
future matisse/vlti instrument (lopez  ) in the l
band (3m).
the different ways of filling the  plane,
  illustrated by matisse observation in the l band (3.5–4.1m) of
  the star  velorum (declination ). “2t” means “2
  telescopes”, “4t” means “4 telescopes” and “4t+conf” means
  “4 telescopes and change of configurations”, i.e. the best
  situation at vlti today
single measurement      wavelength coverage    supersynthesis     supersynthesis  
+ wavelength coverage 
2 t    
 valign=m
    
    
valign=m 
    
    
 valign=m
    
    
 valign=m
    
4 t    
 valign=m
    
    
valign=m 
    
    
valign=m 
    
    
 valign=m
    
 
  
4 t + conf    
 valign=m
    
    
 valign=m
    
    
valign=m 
    
    
valign=m 
    
§.§ the phase problem
so, we have a way to measure the complex visibility. however, the
actual measurement of the fringes is affected by a series of effects
we detail here, and we explain a set of workarounds on how to measure
the amplitude  and phase  of the object of interest. the
effects can be classified into visibility attenuation factors  and phase factors . the following list is ordered by
decreasing magnitude on the observables:
eginitemize
* the atmospheric turbulence adds a phase term  between
  the telescopes, sometimes called “atmospheric piston” because it
  comes from a change in the optical path difference 
  between the two telescopes. this term varies as  as a first approximation (see an
  example phase shape in fig. ).
* atmosphere also puts higher-order terms (like the tip/tilt
  effect) which will affect the instantaneous flux  and . it
  can also affect other terms due to the speckle
  pattern (mourard  ) but today most of the combiners
  use optical fibers to wash out this effect, so we will not detail it
  here.
* a finite exposure time can also be of trouble, as it transforms
  the phase term variations  into contrast variations
  
  (tatulli  ).
* chromatic longitudinal dispersion makes the optical path delay
   dependent of wavelength . this effect
  is explained in details in tubbs  () and vannier  .
* polarisation effects, either in the beam feeding or inside the
  instrument can make the contrast time-variable and even kill it. the
  contrast variation due to polarisation is noted:
  . this is due to a difference of speed propagation
  between the two linear polarisations (birefringence effect) due to
  asymmetric setups or birefringent materials in the instruments
  (e.g. optical fibres). one can then extinct one of the polarisation
  to avoid this effect by using a linear polarizer, or an elegant
  solution is to introduce a birefringent plate with relevant
  properties to compensate for this effect (lazareff  ).
in addition to these effects, more fundamental effects like photon
noise  or detector noise , grouped
in additive noises , need to be taken into account.  to
summarize, one can include all these effects into the interferometric
equation  and consider an arbitrary number of
telescopes , which can be written as:
i    =   ∑_j=1^ ntel i_j 
       +   ∑_k=
       1^ ntel-1∑_j=
        k+1^ ntel i_j i_k
      a(σ_ϕ^p) a(δ_π) a(δ) μ^ obj_j,kcos(
      2 π/λ(x + δ) + ϕ^ obj_j,k)
       +    b
where  are telescope indices;  is a space coordinate;
 is the wavelength;  and  are
the object's visibility and phase;  is the atmospheric optical
path difference (opd), varying with time (see
fig. ). all the beam intensity terms  and 
depend on space , wavelength , and time ;
 is an attenuation factor coming from the finite
exposure time of each frame, and depends on the atmospheric
conditions, or the fringe tracker performances;  is an
attenuation factor dependent of the spectral resolution of the
instrument and the value of the opd ;  is an
attenuation factor depending on the polarization state of both
contributiong beams; finally,  is a zero-mean noise.
[t].3
[t].58
from left to right: example amber spectrally dispersed
  fringes, the corresponding phase, and a time-sequence of
  opd from tatulli  (). reproduced with permission. 
the consequence of the phase problem is that the object phase cannot
be measured directly. the following section provides some guidelines
on how to cope with this fact.
§ observables
the goal of observables is to extract the relevant information,
i.e.  and  from the somewhat perturbed
equation  compared to
eq. .
§.§ squared visibility
one way to minimise the turbulence effect of the phase on the
visibility is to take profit of the developments made for speckle
interferometry in the 70's
(labeyrie ). indeed, the modulus of the
instantaneously-measured complex visibility can be computed and
averaged over time, minimising the effects of phases fluctuations. to
simplify the calculations, one can remove the square root of the
modulus, hence calculating squared modulus. with the fourier method,
this gives:
here one can see that most of the phase effects wipe out from this
visibility estimate, but there are a number of issues related to it:
eginitemize
* additive noises can lead to biases (see how to treat them
      in perrin , and also in this book:
      ten brummelaar ),
* the multiplicative terms , , and
       in eq.  do not
      wipe out from the estimator, making calibration a very acute
      issue for this type of estimator (see for example
      millour  ).
in terms of error estimate, the squared visibility method has a
well-documented bibliography and i would suggest reading one of these
papers: tatulli  (), petrov  (), or ten
brummelaar ).
§.§ differential visibility, coherent visibility
another way to minimize turbulence on the visibility measurement (the
terms  and ) is to
wipe it out explicitely.
in other words, as shown in fig. , the phase as a
function of  exhibits a “slope”, directly related to
opd. this provides us a way to measure .  the
coherent flux  of
eq.  can be corrected from the associated phase
term, and its real part averaged.
this estimator of visibility is calculated by the midi pipeline
(koehler  ) and is planned to be implemented
in the matisse instrument too. it is often called “coherent
visibility” or “linear visibility”. many aspects are not treated
here (like e.g. time-averaging) as these are pure signal processing
aspects (you can refer to papoulis  to see
how time-averaging of the quotient of two random variables can be
done) and they would be too long to describe here.
to overcome the  term, supposedly
wavelength-invariant, it may be convenient to divide the above
estimate of visibility by its wavelength-average. this provides a
visibility measurement whose average value is 1 and whose variations
with respect to wavelengths are kept. it is then called “differential
visibility” as its variations are only relevant relative to a virtual
reference wavelength (also called “reference channel”).
two flavors of differential visibility may be computed:
eginitemize
* normalizing the squared visibility of eq.  by its wavelength-average.
* normalizing the linear visibility of eq.  along .
the first method was used in the early times of amber. the
second method is the one proposed today in the amber data
reduction software, and also on vega. it will be proposed also
for matisse. i would suggest reading the papers millour
() and mourard et
al. () for more information.
§.§ closure phase
the phase  of the object is usually considered as lost
when going through the atmosphere. however, a phase measurement out of
3 telescopes was invented for radio-astronomy
(jennison ), called “closure phase”. this
closure phase has extremely interesting properties in that it washes
out the atmospheric disturbances from the phases.
let us call  the three telescopes of interest. the object's
phases are, according to the zvc theorem, linked with each baselines
, , and . on the other hand, the atmospheric disturbances affect the
phase of the wavefront prior each telescope, hence the
atmospheric phases can write  
. baseline-wise, the phases can be expressed then:
φ_1,2    =    ϕ_1,2^ obj + ϕ^ atm_2 - ϕ^ atm_1 
    φ_2,3    =    ϕ_2,3^ obj + ϕ^ atm_3 - ϕ^ atm_2 
    φ_3,1    =    ϕ_3,1^ obj + ϕ^ atm_3 - ϕ^ atm_1
when summing the phases from the three baselines, the atmospheric
disturbances disappear and the summed phase becomes:
this is called the closure phase. however, one cannot simply sum the
phases, as the phase noise is usually very large compared to 
(or 1 rad). the phases histogram can therefore be very far from a
pristine gaussian distribution, often close to an uniform
distribution. the corresponding phase-wrapping effect is illustrated
in fig. .
illustration
 of the phase wrapping effect, showing the transition of phases
 histograms from almost gaussian to a nearly uniform distribution. the
 top part shows the real and imaginary parts of the complex values,
 while the lower part shows the corresponding phase histograms. the
 three first panels are synthetic data, while the last one is actual
 very high signal-to-noise ratio amber
 data.  
the way to compute it as an observable is to compute the
bispectrum directly in the complex plane, average it
and then take the phase:
when the three visibilities on the three baselines have similar
values, the closure phase noise is just  higher than the
true phase noise. however, this is not true at all when the three
baselines have very different visibility amplitudes (for example when
one baseline is exactly in a zero of visibility). in such a
case, the closure phase noise is approximately equal to the highest
phase noise from the three baselines. one can refer to
chelli  () for more information.
for details on what means the closure phase, and how to interpret it,
please read section .
§.§ differential phase
§.§.§ how to get it
“differential phase” can mean many things: the phase difference
between the two telescopes (what has been called “phase” in this
paper), the phase difference between two offset positions (also
referred as “phase referencing”), the phase difference between two
separated beams (aime  ), or the phase
difference between two adjacent wavelengths, introduced by beckers
(). we will not talk about the three first
phases, but explain here the last one which had quite some
applications in the last decade for optical interferometry.
if we take a look to the phase term in
eq., we note it is made primarily of
two components:
these two components are the object's phase , basically fixed as a function of time (if there
is no baseline smearing) but possibly varying as a function of
wavelength (for example inside an emission line, or as a function of
spatial frequency), and the opd term 
strongly varying as a function of time. all higher-order terms (like
the water vapor term) are contained within the term
.
if one is able to estimate properly the opd term, it can be subtracted
from the individual phase measurements, and the remaining phase
variations as a function of wavelength can be averaged. to avoid
wrapping effects in presence of noise, this procedure must be done in
the complex plane, by computing a cross-spectrum:
we note here that we remove only the achromatic opd effect, but as
mentionned in page item:chromaticopd, other effects can also
affect the phase. they are present essentially as a phase offset plus
higher order terms. the phase offset can be removed by computing
phase differences between the current wavelength (called “work
channel”) and another wavelength (called “reference channel”,
bearing many similarities to the one used for differential
visibility), i.e.:
one can note here that equations  and
 can be swapped in the process without any
issue.
the reference channel can be computed by taking one wavelength, or by
averaging several wavelengths. the most used method is to compute the
reference channel with all but one of the wavelengths (to avoid
introducing a quadratic bias). the differential phase can be related
to the object phase according to the following equation:
where  is the number of wavelengths in the reference
channel, and “1” is the one wavelength in the work channel. the
small multiplicative factor  has to be
taken into account due to the definition of the reference channel, as
detailed in millour () page 91. usually, this
factor is negligible, as most today spectro-interferometric
instruments have 100's of channels, but it may be large-enough for
wideband instruments to be considered. the two terms  and
 are lost in the process, but may be recovered by using the
self-calibration method (see sect. ).
§ interpreting interferometric data
what has been described in the previous sections is how to obtain
interferometric data, but no word has been written about how to
interpret these data. the goal of this section is to see how to
compare interferometric measurements with a model, the image
reconstruction part being treated in a separated article (young &
thiébaut , this book). we divide this section in two
sub-sections: qualitative interpretation of data (“first sight”
interpretation) and quantitative interpretation, with a few examples
of implementations.
§.§ first-sight interpretation
§.§.§ description of observables
interferometer data usually come as optical interferometry flexible
image transport system (oifits) data files, which are based on the
fits format. for more information on the oifits specifications, see
pauls  (). most of the
time, an oifits file contains squared visibilities, plus optionally
closure phases and/or differential visibilities and differential
phases, depending on the instrument used. 
these different observables provide already some information on the
object. table  presents some simple examples of
the considerations you can make at “first sight”. for example, a
visibility close to 1 is measured with a 130 m baseline in the
near-infrared for an object much smaller than 2 mas, i.e.  smaller
than the angular resolution
. 
more generally,
the visibility value indicates whether the object is resolved
  (low visibility) or not (visibility close to 1).
the differential visibility is a relative measurement of the object
     size along wavelengths. a lower differential visibility in an
     emission line indicates an emitting region larger than in the
     continuum.
the phase is sensitive to astrometric position of a given
     source. as such, it provides both information on the asymmetry
     (skewness of the intensity distribution) of the object and its
     photocenter (astrometry).
the closure phase gives the information whether the object is
     asymmetric (skewness): a zero or  closure phase may
     correspond to a symmetric object (but not in 100% of the cases),
     whereas a non-zero closure phase (modulo ) indicates for
     sure an asymmetric object. the astrometric position is lost in
     the closure phase signal.
the differential phase is sensitive to the astrometric position
     at one wavelength relative to another wavelength. therefore,
     astrometric shifts in emission lines can be measured with it, or,
     if a large chunk of wavelength is available, it allows one to
     scan phase across spatial frequencies for an achromatic object
     (like a binary star for example). it contains also the
     information of the closure phase wavelength-variations, the only
     relevant information coming from closure phase being then its
     wavelength-average value.
a few example of qualitative features seen on the above observables
and their signification are provided in table .
qualitative information which can be retrieved from
  interferometric observables. 
    observable     value or features     qualitative information     model-fitting guidelines     illustration 
table 
visibility     close to 0     object  rad     add a resolved component     (a) 
close to 1     object   rad     uniform disk size     (e) 
cosine shape     binary star!     use a binary model     (i) 
diff. vis.      in an emission line     bigger emission     add an emitting envelope     (c) 
in an emission line     smaller emission     add an inner region/disk      (g) 
in an absorption line     central object in absorption     absorbing central object     
in an absorption line     shell in absorption     absorbing shell      
clos. phase      and      asymmetric object     add a point source     (f) 
or      object possibly symmetric     -     (b) 
diff. phase     sine shape     binary star!     use a binary model     (k) 
“s” shape in a line     object is rotating!     use a kinematic model     (h) 
“v” shape in a line     asymmetric object in line     see weigelt  ()     (d) 
“w” shape in a line     a bipolar outflow?     see chesneau  ()      (j) 
the optical long-baseline interferometric “observables zoo”, showing all the different cases one can face with current spectro-interferometric instruments, illustrated with actual published interferometric data. the letters link to the table . reproduced with permission.
visibility     closure phase     diff. vis.     diff. phase 
(a) resolved source     (b) zero     (c)  in emission line     (d) “v” shape
benisty  ()     monnier  ()     stee  ()     weigelt  () 
(e) unresolved source     (f) non-zero     (g)   in emission line     (h) “s” shape
demory  ()     monnier  ()     kraus  ()     meilland  () 
3-3
(i) cosine shape           1c(j) “w” shape     (k) sine shape
meilland  ()         1cchesneau  ()     meilland  ()  
1c
    
    
§.§.§ what can i do without a model?
already a significant amount of things! the visibility, closure phase
and differential phase provide already a large number of information
about the geometry of an object.
in practice, two quantitative information can be extracted from the
visibilities and differential phases without a model:
eginitemize
* size estimate with the visibilities (if the visibility is larger
      than 20%), using simple ad-hoc models (like uniform disks:
      demory  ), gaussian disks:
      tristram  , or even rings:
      kishimoto  ,
* photocentre  variations with the differential phase, or
      spectro-astrometry, using the simple relation  when an object is unresolved.
however, one needs to bear in mind that these quantitative estimates
are valid only when the object is barely resolved. for more
details, please read lachaume (). in all
other cases, on needs to use a model-fitting tool like 
(tallon-bosc  ),  (millour et
al. ), or  (kloppenborg et
al. )
§.§ quantitative interpretation: model-fitting
when one has a model  of an object, with parameters , and
wishes to compare it with the data acquired, one needs to quantify how
the model matches the data. this match is perfect when the synthetic
observables computed from the model  are equal to the
observations, described by the measurements :
however, this never happens due to the presence of noise. one way to
best match the model to the data is to compute squared differences
between  and , taking into account the noise :
minimizing this quantity by changing the parameters values  provide
a plausible solution to the eq. . this minimization
is made by an optimization algorithm, and the whole process is
called “model-fitting”. 
specific aspects of long-baseline interferometry, like the use of
wrapped phases (see fig. ), heterogeneous data
noise models (schutz  ), or highly
non-convex , need to be taken into account. this is why
specific software have been developed to cope with it. they are
basically made of an oifits reader combined with a
simplified instrument model, and they make use of
different optimizers going from simple descent algorithms up to
simulated annealing, or mcmc methods.
the whole process is described for the specific case
of  in tallon-bosc  (). you
can also have a look to the practice sessions in this book
using  (domiciano ).
the model itself  may be a simple analytic model (“toy”
model, described in sect. ), very fast to
compute, or an image coming from a more advanced model (described in
sect. ).
§.§.§ analytic models
the space distribution of light may be described by simple analytical
functions, as is the associated visibility. due to the zernicke &
van-cittert theorem, these visibility functions are the fourier
transforms of the image functions. the most common analytical
functions are given in table  and provide already a
quite complete overview of what is used nowadays to interpret
interferometric data.
analytical models of different shapes and their associated
  visibility function. the following parameters are used:  represents either the diameter for a ring or uniform disk, or
  fwhm.  or  represent the angles in the image
  plane.  or  are the spatial
  frequencies.  
shape     brightness distribution     visibility 
point source          
    
background          
    
    
binary star         
    
gaussian    
          
uniform disk     
    
        
ring          
    
exponential     ,       
any circular object           
pixel (image brick)   
    
        
    
limb-darkened disk     
    
         
    
    
with ,  analytical functions like the ones described in
table , ,  are coordinates in the image plane,
 and  are spatial frequencies, and  and  are
zoom & shrink factors.
all these analytical models can be added together to produce combined
models. this is feasible thanks to the linearity of the fourier
transform, and other properties described below:
§.§.§ generic properties of fourier transform
here i describe the generic properties of the fourier transform, which
can be found in any book treating ft. 
these properties are widely used to combine or to modify, stretch,
distort, the simple analytical models provided above:
•  linearity (addition): ,
• translation (shift): ,
• similarity (zoom and shrink): ,
• convolution (“blurring”): ,
•  limit (“small” details): ,
•  limit (“large” details): .
these fourier transform properties can also be used to combine more
advanced models. this was for example the case of millour (), where the authors combined a series of ring
models to build the pseudo-3d toy-model of a spiral nebula.
§.§.§ advanced models
for more advanced models, which do not have a simple analytical
expression, one can produce a pixellized map of the model and
fourier-transform it. most model-fitting software allow, or are
planned to allow to fourier-transform maps of otherwise computed
models. this is for example the case
of , , and will be in a near-future in
the distributed version of .
§.§ image reconstruction
image reconstruction is treated in details in young &
thiebaut () later in this book. i invite the
reader to take a look to that article.
§.§ the advent of differential phase
differential phase has changed the panorama of possibles in
long-baseline interferometry. millour ()
presented a theoretical approach to explain the potential of
differential phase to bring new information, independent of a model,
to model-fitting and image reconstruction. as this work in in french,
i translate most of the related content here to the english reader:
§.§.§ potential in model-fitting
i was interested here to quantify the information brought by
differential phases in addition to the one brought by closure
phases. i took inspiration from the demonstration of lachaume
() and considered first a n-point-sources
model, but resolved by the interferometer. these sources are described
by  parameters for position (global centroid is unknown
and all sources coordinates are described relative to the first one),
and  fluxes, i.e.
no other hypothesis is done otherwise than observing several sources
at many wavelengths simultaneously. great.
accounting for the number of observables will help us quantify the
maximum number of sources that can be modeled . this
maximum is given by zeroing the degrees of freedom of the
model-fitting problem (i.e. modelling  chromatic
point-sources and comparing them to the interferometer data). these
degrees of freedom  are simply the difference between the
number of independent observations  and the number of
parameters of the model , i.e. . zeroing it is simply writing the equation:
the users of interferometers can face four specific cases:
full access to the complex visibility:
this is for example the case in radio-astronomy, or the dream of every
single optical interferometrist. in this case, one has access to
 visibilities,
the same number of phases, and  measured fluxes (the
spectrum). we therefore have:
putting equations  and  into
equation , we get:
we see here that the maximum number of sources is roughly proportional
to the number of baselines (i.e. square the number of telescopes), but
not to the number of wavelengths. on the wavelength side, the increase
of the number of sources has an asymptotic behavior.
visibility only:
this is the case with 2-telescopes instruments like vinci, classic,
fluor or midi. in this case, one has access to  visibilities and 
measured fluxes (the spectrum). we therefore have
that number is roughly half the number of
eq. . this is expected as we measure only
half the information on the object (no phases).
putting equations  and  into
equation , we get:
visibility and closure phase:
this is still today the most common case. in such a case, one has
access to 
visibilities,  closure phases and still  measured fluxes. therefore,
we therefore have the following:
the same comments as before applies here, except that the term
 grows faster than the term  of the previous paragraph.
visibility, closure phase and differential phase:
this is the case of amber, matisse and gravity. the
observables are now  visibilities,  differential phases,  closure phases and still 
measured fluxes. however, one has to note that closure phase and
differential phase are not independent measurements. indeed, they are
both related to the object phase (see eq.  and
eq. ). therefore, one can write the relation
between the differential phase and the closure phase using both
equations:
the careful reader should have seen here that i discarded the small
term , which can be neglected for a
large number of spectral channels. one can also note that one of the
terms  can be fixed to
zero in order to set the two other offsets, and therefore fix the
global photocenter of the object (which remains unconstrained by
closure phases and differential phases).
this equation and the above additional constrain provide us with the
relevant information: the closure phase bring only additional data on
two offsets  and wavelength-slopes
 that are missed by differential
phases. all other information (wavelength variations) are contained
both in closure phase and differential phases. therefore, the closure
phase provides  independent
observables instead of the  accounted just before.  therefore, we get:
and the maximum number of sources that can be modeled is:
these different cases are illustrated in
fig. . we see that, typically
above 20 spectral channels, the use of differential phases put us in a
case almost similar as if there was a true phase measurement for
model-fitting. this was the main motivation to develop the
model-fitting tool , which can make use of chromatic
parameters.
illustration
    of the potential of using the differential phase in model-fitting
    or image reconstruction for 3 nights of 4 telescopes observations
    (like in the case of matisse) compared to other cases. left: modelling  point-sources, the green dashed
    line using visibilities and phases, the black solid line is using
    visibilities alone, the red dotted line using visibilities and
    closure phases, and finally the blue dash-dotted line using
    visibilities, closure phases and differential phases. right:
    reconstructing a  pixels
    chromatic image. the colours are the same. 
§.§.§ in image reconstruction
the wavelength-differential phase was not considered in imaging until
millour (), schmitt  () and millour  (). indeed, differential phase provide a corrugated
phase measurement (as described in eq. ), which,
in theory, can be incorporated into a self-calibration algorithm, in a
very similar way as what is done in radio-interferometry (pearson &
readhead ).
as early as , j. monnier anticipated
“revived activity [on self-calibration] as more interferometers with
‘imaging’ capability begin to produce data.”
and indeed, the conceptual bases for using differential phases in
image reconstruction were laid in millour
(): the same reasoning as in the previous
section can be applied, except that an image is made of pixels whose
positions are pre-defined. the only unknown information is therefore
the spectrum of each pixel. if  is the image size ( for a 128 x 128 image), the number of unknown  is
equal to:
and the maximum number of pixels that can be reconstructed is:
full access to the complex visibility:
  
visibility only:
  
visibility and closure phase:
  
visibility, closure phase and differential phase:
  
fig.  shows the same behavior as
for model-fitting: typically above 20 spectral channels, the use of
differential phases put us in a case almost similar as if there was a
true phase measurement, i.e. as if there was no atmosphere in front of
the interferometer, given that one is able to take profit of the
information contained in the differential phase.
the schmitt  () paper was a first
attempt to use differential phases in image reconstruction. they
considered that the phase in the continuum was equal to zero, making
it possible to use the differential phase (then equal to the phase) in
the h emission line of the  lyr system. they were able
this way to image the shock region between the two stars at different
orbital phases.
the paper millour   went one step further, by
using an iterative process similar to radio-interferometry
self-calibration (pearson & readhead ) in
order to reconstruct the phase of the object from the closure phases
and differential phases. this way, they could reconstruct the image of
a rotating gas+dust disk around a supergiant star, whose image is
asymmetric even in the continuum (non-zero phase). this method was
subsequently used in a few papers to reconstruct images of supergiant
stars (ohnaka  ). a more
recent work (mourard  ) extended the method to
the visibilities, in order to tackle the image reconstruction
challenges posed by visible interferometry, lacking the closure phases
and a proper calibration of spectrally-dispersed visibilities. the
image-cube reconstructed with this technique in mourard () is shown in fig. .
image
    from mourard  (), showing the kinematics
    of the  per be star disk through the h emission
    line. the top row shows the reconstructed images, the middle row a
    best-fit kinematics model and the lower row a reconstruction based
    on the model, for comparison. reproduced with permission.  
of interest are also new developments made on the core image
reconstruction algorithms to include the differential phases into the
process (schutz  , or
soulez  ). these new algorithms are
very promising and they must be confronted sooner or later to real
datasets.
§ interferometry hardware
combining telescopes which are hundreds of meters apart is a difficult
matter, which needs a set of functions described below and shown in
fig. :
eginenumerate[(a)]
* telescopes, to collect the light, mostly defined by their
      diameter ,
* set of periscopes (sometimes grouped in “switchyards”) to shape,
      collimate, and feed the beam through light tunnels, defined by a
      fixed length ,
* delay lines to compensate for the variable delay due to pointing
      the telescope and the atmosphere's effects, defined by a
      time-variable optical path length ,
* combiner instrument to effectively produce the interference
      pattern.
we will try not to repeat the numerous descriptions of how to build an
interferometer. 
we just describe here what makes an interferometer working:
§.§ telescopes
interferometry telescopes are, in principle, no different from
“regular” astronomical telescopes. however they differ on three
aspects we will detail in the following subsections: they must be
smart, tough and large.
§.§.§ “smart”
a “smart” telescope is a reliable one. indeed, a single telescope
needs to be operational (i.e. not undergoing technical failures or
maintenance) most of its time.
for example, if we take the eso telescope
schedule[]
for the unit telescopes on the vlti, the observatory confidence in their
telescopes is given by the ratio of observing nights scheduled by the
available clear skies observing nights (lombardi  : 310
  nights/years at paranal). this is illustrated by
figure  where we provide the number of scheduled
nights (visitor or service mode) versus the average number of clear
nights at paranal. eso usually accounts for reliable telescopes 89%
of the clear sky time.
on the other hand, the vlti scheduling, illustrated in
figure  tells us that the eso observatory uses 50%
of the available clear sky nights, after a learning curve on the
interferometer between 2003 and 2006. this is well explained if we
consider all 4 telescopes are used for interferometry. the probability
of having all 4 telescopes online in a given night is just
 of the available time. the difference between the two
numbers (50% and 63%) comes from the numerous additional sub-systems
needed by the vlti to operate (delay lines, fringe tracker,
instrument, etc.).
left: vlt scheduling taken from the eso telescope
    schedule, including all 4 unit telescopes (hence # of nights
    multiplied by 4). different colours represent different times on
    the telescopes. the dashed line represent the clear skies night,
    while the dotted line represent the total number of nights over
    one observing period (6 months). right: the same plot for
    the vlti.
  
a word on the “technical” time plotted here: the cumulative time,
including technical one, exceeds the number of clear sky nights, since
some technical activities do not need the telescope open. we also note
here that the vlti technical time was not fully taken into account in
the scheduling until 2008, leaving the impression that the vlti was
“idle” most of the time.
§.§.§ “tough”
a “tough” telescope is a stable one. “stable” means the telescope
do not transmit vibrations to the instrument. usual instruments at the
focus of telescopes are sensitive (at first order...) to transverse
vibrations (i.e. “tip/tilt” vibrations). this puts some requirements
on the tip/tilt pointing and stability accuracy (see for example a
study in altarac  ).
unfortunately, an interferometer is sensitive both to transverse
and longitudinal vibrations (a.k.a. “opd” or “piston”
vibrations). both of the large telescopes interferometers are subject
to such vibrations as they were not designed in the first time to be
used in an interferometer (hess  , millour  ). to
overcome these effects, an active dampening system had to be
integrated into both facilities (hess   , lizon  , poupar  , spaleniak  ).
on smaller telescopes facilities, vibrations have also been
investigated but this effect has a much smaller amplitude
(merand  ).
it is worth to note that the vlt instruments are themselves affected
by vibrations (sauvage, private communication), and vibrations
assessment are a part of the elts design.
§.§.§ “large”
“large” telescopes means large collecting area, means more sensitive
interferometer. however, one needs to bear in mind that the gain in
sensitivity is true only for a constant strehl ratio of the
telescope psf, simply because the overall effective transmission of
the system, when using optical fibres, is multiplied by the strehl
ratio. this is why very large telescopes interferometers (vlti
& keck) have been equipped with adaptive optics (arsenault  ).
§.§ feed through
the light is fed by a series of mirrors from the telescope to the
delay lines building. this is where a large part of the light
propagation occurs in the interferometer and where potentially several
issues can happen to the beam. three possibilities exist today to
transport the beam:
eginitemize
* through air (e.g. in vlti and keck-i),
* through vacuum (e.g. in iota, chara, npoi),
* through fibers (developed for the ohana
  project, woillez  ).
the air transportation is the simplest to setup with just tunnels and
relay optics to be installed (no bulky vacuum tubes and
pumps). however, the air introduces chromatic longitudinal dispersion
when large delays are compensated, which affects the fringe signal and
is not easy to overcome for high-precision measurements
(tubbs  ,
vannier  ).
how to combine beams from separated telescopes illustrated
    with the vlti. the collected beams are first collimated and fed
    into tunnels by a set of mirrors in the telescopes, put into delay
    lines to compensate for the delay introduced by pointing and other
    effects (in red), then fed into the interferometric instruments
    that records the data.
  
§.§ delay lines
delay lines are a set of movable mirrors which compensate for the
optical delay induced by the pointing of the telescope. these are
supposedly simple at first glance but one needs to consider the
required precision (less than 1), and range of motion (half the
largest telescope baseline, i.e. it can be hundreds of meters). these
optical systems are in no way simple to build and operate, as the
mirrors-bearing carriage has to provide sub-micron position accuracy
on hundreds of meters with a continuous motion of a few centimetres
per second...
several technical solutions have been implemented, which all have
advantages and drawbacks: the delay lines can be in the air (like on
vlti or keck-i) or in vacuum (like on iota), or partially
in vacuum and partially in air (like in chara, npoi). they
can be one stage (vlti) or two stages (iota, keck-i, chara, npoi) with a long-stroke fixed delay (easier to
manufacture) and short-stroke moving delay.
§.§ combiner
the last element of the interferometer is the combiner. it is
basically a michelson or a fizeau interferometer plugged-in to a very
sophisticated video camera with some degree of spectral dispersion and
a feedback loop to stabilise the fringes.
the fringe combination can be done in different ways and we refer the
reader to berger (, this book) for further details.
all these sub-systems are shown in the illustration
fig. .
§ optical interferometry in 2015
§.§ vlti
the vlti is the only large-aperture interferometer in operation
today. with its four 8-meter class telescopes, supplemented by four
movable 2-meter class telescopes (see fig ), it
offers versatility and sensitivity at the same time. it saw its first
light in 2001 (glindemann  ) with the
vinci instrument, and has since seen its capabilities
increasing: 2 recombined telescopes in 2001
(kervella  ), mid-infrared with midi (leinert  ), 3 telescopes and a
high spectral resolution in 2004 with amber
(petrov  ) and 4 telescopes in 2010
with pionier (le bouquin  ,
but lacking a high or medium spectral resolution, and just open to the
general community since 2015). the vlti is noticeably the most
productive interferometric facility in the world (see
fig. ). applying for observing time is open to any
professional astronomer, and its archive is public after typically one
year of ownership by the pi. the next generation instruments matisse and gravity will offer to the wide community four
telescopes and, for the first time, real imaging capabilities.
publications related to long-baseline interferometry per
    year (data from the jmmc ). the
    dash line represent the total number of publication whereas the
    colors are per facility (i.e. observations papers only). we can
    see a steep increase after 2002 with the advent of vlti, and a
    decrease after 2010 due to the closure of several facilities
    (keck-i, iota, ...).
  
§.§ chara
chara is a six-1-meter-class telescopes interferometer, which is
funded and operated by the georgia state university. it has developed
in the 2000s a collaborative framework allowing teams from all over
the world to install and operate instruments on the facility. as a
result, chara is the interferometer with the most number of
currently-operated instruments, with classic, climb, mirc, pavo, vega. chara has the longest operating
baselines (300 m) and works in the visible range, making it the
sharpest telescope on earth.
§.§ npoi
npoi is a six-telescope interferometer jointly operated by the
lowell observatory and the us navy. it consists of small apertures
movables siderostats for imaging as well as fixed siderostats
dedicated to astrometry. its recent developments include a 6-telescope
visible instrument vision and the commissioning of new longer
baselines. it is currently limited by the small apertures, but the
developement plan includes the installation of meter-class telescopes
in the future.
§.§ the legacy
the long-term durability of the data acquired by the interferometers
make it a goldmine for future astronomers. therefore some
observatories have made an effort to archive the obtained data and to
make it public for future use. this is e.g. the case for the eso
science archive facility[available at
  ] which provides raw datasets from all
the open vlti instruments plus, more recently, data from the visitor
instrument pionier.
since eso provides only raw datasets, a community effort is being made,
led by jmmc[available at ],
to provide a reduced database called oidb. it will provide in a
near-future reduced datasets which have been published, in order to
make them accessible for future use.
an effort has also been conducted to make the legacy keck-i and pti
instruments data avilable through the pti & keck public
database[available
at ]. future
users can access freely these data and use them in a publication
provided they follow the publishing guidelines available at eso and
nexsci webpages.
§ the future: new instruments, new possibilities
the vlti has been at the leading edge for optical interferometry
in the last decade. however, the two first-generation instruments,
amber and midi are now 10 years old, and even though they
have unmatched features (high spectral resolution for amber and
n band for midi), they start to show their limits. therefore,
eso issued a call for proposals in 2005 to build second generation
instruments. two projects were selected: gravity[], aiming at
performing micro-arcseconds astrometry on the galactic center in the
near-infrared, and matisse[], aiming at opening
the l band in addition to bring imaging capabilities to the vlti
in the mid-infrared. they both come to the sky in the 5+ years from
now.
the chara array is being fitted with adaptive optics to improve
by a large factor its performances, especially at short wavelengths,
offering new possibilities of performant instrumentation in the 5+
years to come.
in the meantime, several projects have emerged to pave the way of
future facilities: a visible interferometry prospective is being
conducted today (stee et al. in prep.), to make emerge a new
generation instrumentation at vlti and chara in the 10+
years; a more general prospective is conducted by the europan
interferometry initiative to direct future instruments in the same
timeline (pott, private communication); the planet formation imager
project (kraus  ) aims at imaging and
characterizing an exoplanet in the 20+ coming years; finally several
bold prototypes of completely new combination schemes (le
coroller  ,
labeyrie  , and see also the
conclusion of this book:
labeyrie ), hypertelescopes, are being
imagined, developed and tested to gather the technologies necessary
for the 40+ years to come.
acknowledgements: the author would like to thank r. petrov, a. meilland and g. dalla vedova for reading through this paper and for suggesting improvements. thanks also to j.-f. sauvage for interesting discussions about technical aspects on the vlt, and to j.-u. pott for pushing the prospective on the future of interferometry.
99
natexlab#1#1
[1921]1921apj....53..249m
michelson, a. a. & pease, f. g. 1921, , 53, 249
[1958]1958mnras.118..276j
jennison, r. c. 1958, , 118, 276
[1970]1970aanda.....6...85l
labeyrie, a. 1970, , 6, 85
[1982]1982acopt..29..361b
beckers, j. m. 1982, optica acta, 29, 361
[1984]1984araanda..22...97p
pearson, t. j. & readhead, a. c. s. 1984, , 22, 97
[1986]1986josaa...3.1001a
aime, c.; borgnino, j.; martin, f. et al. 1986, , 3, 1001
[1988]perez1988
pérez, j. p. 1988, optique géométrique et ondulatoire, masson
[1992]1992araanda..30..457s
shao, m. & colavita, m. m. 1992, , 30, 457
[1994]1994aanda...288..675m
mourard, d.; tallon-bosc, i.; rigal, f. et al. 1994, , 288, 675
[1999]1999aspc..194..264b
berger, j.-p., schanen-duport, i., el-sabban, s., et al. 1999, in asp
  conf. ser. 194, 264
[1999]bornandwolf1999
born, m., wolf, e. 1999, principles of optics, cambridge university press
[2000]lawson2000b
lawson, p. r. 2000, in principles of long baseline stellar interferometry,
  ed. p. r. lawson, 325
[2001]altarac2001
altarac, s., berlioz-arthaud, p., thiébaut, e. et al. 2001,
  , 322, 141
[2001]2001msngr.104....2g
glindemann, a., bauvir, b., delplancke, f., et al. 2001, the messenger,
  104, 2
[2001]2001sf2a.conf..505l
labeyrie, a. and arnold, l. and gillet, s. et al. 2001, sf2a, 505
[2001]2001aas...198.6104m
merand, a.; ten brummelaar, t.; mcalister, h. et al. aas, 198, 6104
[2002]2002prvs.book.....p papoulis, a. and pillai,
  s. u., 2002, probability, random variables, and stochastic
  processes, mcgraw-hill higher education
[2003]2003msngr.112....7a
arsenault, r. and alonso, j. and bonnet et al. 2003, the messenger, 112, 7
[2003]2003spie.4837..342h
hess, m., nance, c. e., vause, j. w., et al. 2003, spie, 4837, 342
[2003]2003spie.4838..858k
kervella, p., gitton, p. b., segransan, d., et al. 2003, spie, 4838,
858
[2003]2003aanda...400..795l
lachaume, r. 2003, , 400, 795
[2003]2003ap   ss.286...73l
leinert, c., graser, u., przygodda, f., et al. 2003, , 286, 73
[2003]2003rpph...66..789m
monnier, j. d., reports on progress in physics, 66, 789
[2003a]2003aanda...398..385p
perrin, g. 2003a, , 398, 385
[2003b]2003aanda...400.1173p
perrin, g. 2003b, , 400, 1173
[2004]2004spie.5491.1222m
millour, f., tatulli, e., chelli, a. e., et al. 2004, spie,
 5491, 1222
[2004]2004spie.5491.1231p
pauls, t. a., young, j. s., cotton, w. d., & monnier, j. d. 2004, spie, 5491, 1231
[2004]2004spie.5491..588t
tubbs, r. n., meisner, j. a., bakker, e. j., & albrecht, s. 2004, spie, 5491, 588
[2005]2005pasp..117.1255p
pauls, t. a., young, j. s., cotton, w. d., & monnier, j. d. 2005, , 117, 1255
[2006]2006spie.6268e..31l
lopez, b., wolf, s. lagarde, s. et al. 2006, spie, 6268, 31
[2006]2006eas....22..379m
millour, f.; vannier, m.; petrov et al. 2006, eas publications series, 22, 379
[2006]2006phdt........46m
millour, f. 2006, interférométrie différentielle avec amber, phd thesis, univ. joseph fourier
[2006]2006iaus..232..429m
monnet, g. & gilmozzi, r. 2006, in iau symposium, vol. 232, the scientific
  requirements for extremely large telescopes, 429
[2006]2006apj...647..444m
monnier, j. d. and berger, j.-p. and millan-gabet, r. et al. 2006, , 647, 444
[2006]vannier2006a
vannier, m., petrov, r. g., lopez, b., & millour, f. 2006, ,
  367, 825
[2007]2007aanda...464....1p
petrov, r. g., malbet, f., weigelt, g., et al. 2007, , 464, 1
[2007]2007newar..51..597s
segransan, f. 2007, new astronomy review, 51, 597
[2007]2007aanda...464...29t
tatulli, e., millour, f., chelli, a., et al. 2007, , 464, 29
[2007]2007aanda...474..837t
tristram, k. r. w.; meisenheimer, k.; jaffe, w. et al.  2007, , 474,
  837
[2007]2007aanda...464...87w
weigelt, g. and kraus, s. and driebe, t. et al. 2007, , 464, 87
[2008]koehler2008
köhler, r. and jaffe, w., 2008
power of optical/ir interferometry conf. 569
[2008]2008aanda...489.1157k
kraus, s. and hofmann, k.-h. and benisty et al. 2008, , 489, 1157
[2008]2008newar..52..177m
millour, f. 2008, new astronomy review, 52, 177
[2008]millour2008
millour, f., petrov, r., malbet, f., et al. 2008, in 2007 eso
  instrument calibration workshop, 461
[2008]tallon-bosc2008
tallon-bosc, i.; tallon, m.; thiébaut, e. et al. 2008, spie, 7013
[2009]chelli2009b
chelli, a., duvert, g., malbet, f., & kern, p. 2009, , 498, 321
[2009]2009aanda...505..205d
demory, b. o., ségransan, d., forveille, t. 2009, , 505, 205
[2009]haubois2009
haubois, x., perrin, g., lacour, s., et al. 2009, , 508, 923
[2009]2009mnras.399..783l
lombardi, g., zitelli, v., & ortolani, s. 2009, , 399, 783
[2009]millour2009a
millour, f.; chesneau, o.; borges fernandes et al. 2009, 507, 317
[2009]millour2009c
millour, f.; driebe, t.; chesneau, o. et al. 2009, , 506, l49
[2009]2009aanda...508.1073m
mourard, d.; clausse, j. m.; marcotto et al., 2009, , 508, 1073
[2009]2009apj...691..984s
schmitt, h. r., pauls, t. a., tycner, c., et al. 2009, , 691, 984
[2010]2010aanda...511a..74b
benisty, m. and natta, a. and isella et al. 2010, , 511, a74
[2010]jankov2010
jankov, s. 2010, serbian astronomical journal, 181, 1
[2010]2010spie.7739e.138l
lizon, j. l., jakob, g., de marneffe, b., & preumont, a. 2010, spie, 7739
[2010]2010spie.7734e.101p
poupar, s., haguenauer, p., merand, a., et al. 2010, spie, 7734
[2010]2010spie.7734e.126s
spaleniak, i., giessler, f., geiss, r., et al. 2010, spie, 7734
[2011]chesneau2011
chesneau, o., meilland, a., banerjee, d. p. k., et al. 2011, , 534,
  l11
[2011]2011psi..book.....g
glindemann, a. 2011, principles of stellar interferometry
[2011]2011aanda...527a.121k
kishimoto, m.; hönig, s. f.; antonucci, r. et al.  2011, , 527,
  121
[2011]2011aanda...535a..67l
le bouquin, j.-b., berger, j.-p., lazareff, b., et al. 2011, , 535,
  a67
[2011]2011aanda...532a..80m
meilland, a. and delaa, o. and stee, p. et al. 2011, , 532, a80
[2011]millour2011
millour, f., meilland, a., chesneau, o., et al. 2011, , 526, a107
[2011]mourard2011a
mourard, d., bério, p., perraut, k., et al. 2011, , 531, a110
[2011]ohnaka2011
ohnaka, k., weigelt, g., millour, f., et al. 2011, , 529, a163
[2012]2012aanda...545a..59s
stee, p. and delaa, o. and monnier, j. d. et al. 2012, , 545, a59
[2012]lazareff2012
lazareff, b., le bouquin, j.-b., & berger, j.-p. 2012, , 543, a31
[2012]2012aanda...538a.110m
meilland, a. and millour, f. and kanaan, s. et al. 2012, , 538, a110
[2012]kloppenborg2012
kloppenborg, b.; baron, f. 2012, simtoi: simulation and modeling tool for optical interferometry. available from 
[2013]2013aanda...555a..24o
ohnaka, k., hofmann, k.-h., schertl, d., et al. 2013, , 555, a24
[2014]defrere2014b
defrère, d., absil, o., hanot, c., et al. 2014, in improving the
  performances of current optical interferometers  future designs, 87
[2014]2014_kraus
kraus, s. and monnier, j. and harries, t. et al. 2014, spie, 9146, 120
[2014]mourard2014
mourard, d., monnier, j. d., meilland, a., et al. 2015, , 577,51
[2014]2014arxiv1407.1885s
schutz, a.; ferrari, a.; mary et al. arxiv e-prints, 2014
[2014]2014aanda...565a..88s
schutz, a.; vannier, m.; mary, d. et al. 2014, , 565, a88
[2014]2014ipco.conf..255s
soulez, f. and thiébaut, é. 2014, in improving the performances of current optical interferometers  future designs 255
[2014]2014ipco.conf..175w
woillez, j., perrin, g., lai, o., et al. 2014, in improving the
  performances of current optical interferometers  future designs, 175
[2015]berger2015
berger, j.-p. 2015, this book
[2015]2015domiciano
domiciano, a., 2015, this book
[2015]2015labeyrie
labeyrie, a. 2015, this book
[2015]2015aanda...573a.117l
le coroller, h. and dejonghe, j. and hespeels, f. et al. 2015, , 573, a117
[2015]lena2015
lena, p. 2015, some historical insights on optical interferometry,
this book.
[2015]brummelaar2015
ten brummelaar, t. 2015, classic/climb theory, this book.
[2015]young2015
young, j. and thiébaut, e. 2015, this book
/edocument/
