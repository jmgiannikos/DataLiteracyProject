.
a&a
pasp
spie
further author information:
 send correspondence to f. millour, lagrange, oca, bd de l'observatoire, cs 34229, 06304, nice, france
e-mail: , telephone: +33 (0)4 92 00 30 68, or +33 (0)4 92 07 64 89
/bdocument/ 
data reduction for the matisse instrument
    f. milloura,[  o. chesneau also contributed to the design and specifications of the matisse drs, but passed away before seeing the result.],
           p. berioa,
           m. heiningerb,
           k.-h. hofmannb,
           d. schertlb,
           g. weigeltb,
           f. guittona,
           w. jaffec,
           u. beckmannb,
           r. petrova,
           f. allouchea,
           s. robbe-duboisa,
           s. lagardea,
           a. soulaina,
           a. meillanda,
           a. mattera,
           p. cruzalèbesa,
           and b. lopeza.
auniversité côte d'azur, oca, cnrs, lagrange, france; 
bmax planck institute for radio astronomy, bonn, germany;
chuygens laboratory, leiden, the netherlands.
january 16, 2026
======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================
we present in this paper the general formalism and data processing
steps used in the matisse data reduction software, as it has been
developed by the matisse consortium. the matisse instrument is the
mid-infrared new generation interferometric instrument of the very
large telescope interferometer (vlti). it is a 2-in-1 instrument with
2 cryostats and 2 detectors: one  rockwell hawaii 2rg
detector for l&m-bands, and one  raytheon aquarius
detector for n-band, both read at high framerates, up to 30 frames per
second. matisse is undergoing its first tests in laboratory today.
§ introduction
matisse produces 4-telescopes interferences
which are dispersed onto an infrared detector with a spectrograph,
simultaneously in the l&m-bands (3.5–4.1m & 4.6–5.5m,
respectively), and in the n-band (8–13m). similarly as
amber, matisse uses an all-in-one multiaxial
combination with (si-phot mode) or without (high-sens mode)
photometric separation (see fig. ), but due to the
limits of the p2vm algorithm that were found for the amber instrument,
we chose to use the classical fourier processing instead of a p2vm
algorithm for the data reduction software (drs).
the matisse interferogram  is governed by the
interferometric equation, describing the signal:
i(x,λ, t)     =    ∑_i=1^4 p_i + ∑_i=1^4∑_j=i+1^4
    2 v_ij·√(p_i· p_j)·cos( 2 π·
    f_ij· x + φ_ij) + b
most, if not all, terms of this equation depend on the coordinates 
(position on the detector in the space direction) and 
(position on the detector in the spectral direction), and also time
. however, for clarity, we exhibit their dependence only in each
terms description:  is the flux received on the
detector from the telescope .  denotes the
visibility of the observed object on the telescope pair  (constant
but wavelength-dependent) multiplied by an instrumental and
atmospheric transfer function (an unknown, but supposedly slowly
variable gain ), and  is composed of the
phase of the object (constant but wavelength-dependent) plus the
atmospheric phase errors (depending both on  and ). let
 be the combining baseline, i.e. the separation of each of the
6 telescopes pair as seen by the detector, fixed by construction. the
fringe rate, or frequency, of the fringe pattern is directly linked to
it by . in the case of
matisse, we have  equal to , , , ,
 and ,  being the dimension of the output pupil of
the instrument, right in front of the detector. finally,
 is a dominant and highly variable background
contribution from the warm and turbulent atmosphere, the warm optical
train of the vlti and of matisse itself.  can be up
to  times larger than the flux from the star, and we will see
that mitigating this background contribution is a serious task in the
matisse concept and drs (as it is for any mid-infrared instrument).
[detector fringes] 
expected (left) vs. real data (right)
beams implementation on the matisse hawaii detector
(l-band).  the wide central stripe contains the dispersed
fringes (vertical spectral dispersion), while the 4 narrow
stripes on the side contain the 4 single-telescope
photometry used for flux calibration.
 
§ the data reduction software
 
the matisse drs (called ) aims at producing
science-grade spectra, visibilities and phases out of the matisse raw
datasets. the description of the main algorithms were described in
details in several technical documents, and we report here the
selected data reduction strategy and algorithms that were implemented
in .
it is implemented in ansi c and is fully integrated into the eso
pipeline software (i.e. it is interfaced
with 
and ). the implementation
uses the eso-developped common pipeline library
(cpl), the fits format for intermediate
frames, and the oifits format for the final data products (the matisse drs will
fully support the oifits version 2 format). the 
interfaces are made with xml files and also organisation,
classification, and association rules (oca rules), and the gui part is
coded in python. the consortium actively supports eso in the
integration of  in a  workflow that will
be used both at eso and at the consortium sides for the reduction of
the matisse data.
§.§ overview
the basic input data are the raw frames of the matisse instrument,
stored as fits files. let be  this raw data
intensity at time , given at the  pixel detector
index. compared to the interferogram , the raw data
is affected by the following effects:
eginitemize
* detector bias,
* detector bad pixels,
* detector + instrument flat field, plus eventually non-linear effects,
* instrument distortion map, including a non-linear spectral dispersion law,
all these effects must be removed from the data in order to get the
interferogram of eq. , out of which we extract
the matisse observables. in addition, a calibration process leads to
science-grade data. to do so, the software is organized into a data
reduction cascade (shown in fig. ) that
enables one to produce the calibration maps (,
, ,
), reduce the raw data into oifits files
(), calibrate the data
(), and then reconstruct an image out of the
reduced data ().
the very first step is to estimate the calibration maps like flat
field map, bad pixels map, or distortion map out of calibration frames
obtained during daytime using the internal calibration source of the
instrument. they are used to correct the basic cosmetic of the
detector and some optical effects of the instrument.
[pipeline cascade] 
the matisse 
pipeline cascade, showing all the steps and files necessary
to obtain a final science-grade dataset (calibrated oifits
and/or reconstructed images).  
 
§.§ detector-specific cosmetics
 
§.§.§ bad pixels, flat field
 
the bad pixel map is derived from a series of cold dark raw frames
obtained by increasing the integration time (dit) from the mindit to
five times the mindit with a minimum of 50 frames per exposure:
eginitemize
* first, spurious cosmics are detected by analyzing the intensity
values of each pixel,
* then, a robust median, a mean, and a standard deviation are computed
for each pixel.
* for quality control purposes, the median, mean, and standard
deviation of each pixel median of each series are calculated.
* for each pixel, a straight line is fitted to the 5 different
median values. this fit results in an offset (pixel bias), a slope
(dark current), and a fit quality.
* a pixel is marked as a bad pixel if the fit quality or the
slope exceeds a certain limit (n sigmas of the standard deviation of
the fit quality or slope for all detector pixels).
the flatfield map is derived from a series of illuminated frames
ranging from detector noise up to detector saturation:
eginitemize
* first, the median of the matching series of cold dark frames is
subtracted.
* each frame is processed like the series of cold dark frames,
i.e., mean, median, and rms are computed.
* after normalization, the slopes of the straight lines from the
flatfield images are used to compute the master gain map. however, in
order to get a “detector” flatfield, the non-flat illumination must
be taken into account. therefore, the implemented algorithm must be
adapted to the instrument optics.
the non-linearity map and the flat field are derived by fitting
higher-order polynomials to the exposed frames, and saved as maps into
fits files. we differentiate two types of flat fields in matisse:
the detector flat field, which is obtained by a special device
put into the beam, which diffuses the light onto the detector in a
roughly uniform way, and the observing flat field, which is
obtained through the spectrograph with a white lamp or a star without
spectral features. the first one enables us to correct for detector
pixel-to-pixel gain variations, while the second one allows us to
correct for optics transmission variations.
§.§.§ excess low frequency noise
during the aquarius detector tests, and thanks to the eso experience
with visir, a strong temporal noise was effectively detected in the
data. a set of exposures with increasing dit was taken. this so called
excess low frequency noise (elfn) showed up in the temporal power
spectra, as presented in fig. . pure white noise would
result in a nearly flat temporal power spectrum. the increase at lower
frequencies shows the elfn.
further investigations have lead to the following: the aquarius elfn
is not a simple 1/f noise, the origin of the elfn seems to be inside
the semiconductor diode (pixel), the elfn of different pixels is not
correlated, the elfn could not be reduced by using different readout
modes, different multiplexer clocking schemes and delays or different
bias voltages, the elfn is proportional to the detector output signal
level, elfn cannot be seen in dark images, therefore cds does not
help, and finally elfn was found on other mir detectors (si:as, insb,
etc.).
we expect this effect to be negligible for the coherent flux estimate
(eq. ), but likely present in the photometric
estimates of matisse (eq. ). the mitigation of
this effect will need a fast chopping frequency like in visir, whose
speed need to be addressed on sky.
[excess low frequency noise] 
average temporal power spectrum at
several exposure times and increasing illumination. the elfn
shows up at frequencies lower than 1 hz.
 
§.§ optics calibration
 
§.§.§ camera & spectrograph image distortion
once the bad pixel map and flat field map have been produced, one can
continue the instrument calibration with the determination of the
image distortion. since matisse contains a long-slit spectrograph, the
distortion in the wavelength direction translates into a spectral
dispersion law which is non-linear. we chose to treat the problem
globally by computing a “shift map”.
the shift map is derived from a series of frames containing either a
spatial grid (3 separate holes in the slit direction) or a spectral
grid introduced by carefully-chosen plastic foils (for the wavelength
direction), as shown in fig. . this distortion
estimate will be done at the same frequency as the flat field map or
bad pixel map estimates.
[distortion estimation] 
three panels on the left:
spatial grid, made with three pinholes at different
positions. note that the photometric beams position is
inverted compared to the interferometric beam one. right: spectral grid, made with plastic foils with spectral
features. these snapshots were recorded in the n-band.
 
the distortion can be expressed as the relation between the pixel
coordinates (x, y) and the spectrograph coordinates  on the
detector:
x     =     a(x,λ) x + b(x,λ) λ
    
    y     =     c(x,λ) x + d(x,λ) λ
are the pixel indices, and  are the position and spectral
dispersion, respectively. this can be written as a matrix relation:
what we need then is to invert the matrix  to get the distortion relation:
spatial direction:
the spatial grid is first used. the  parameter is estimated
by fitting a polynomial to the position of the different features
detected on the beams (3 features per beam):
spectral direction:
we are then only interested in determining the -dependent
distortion. therefore, a “normal” -calibration frame
(i.e. with the set of absorption plastic foils, or using sky
absorption lines) should be available for that. in that case, one can
determine the  coefficient:
we note here that this first step will give a coarse
wavelength-calibration, which will be refined in a further step using
telluric lines.
§.§.§ shift and zoom, -matrix
 
as shown in fig.  and fig. , the
matisse photometric beams have a different width than the
interferometric beam, for obvious pixels-saving reasons. therefore,
since the spatial filtering is not perfect (due to the fact that we
use pinholes instead of fibers, for technology readiness reasons), one
needs to scale the photometric beams to the interferometric beam size
by shifting and zooming them to the right place and scale.
in addition, one has to get the flux ratio coefficient between the
flux measured in the interferometric beam and the one measured in the
photometric beam, in order to have all the photometric information
available to compute the observables.
the shift and zoom coefficients, together with the -matrix are
computed using 4 illuminated frames, one for each of the telescope
beams, the other beams being closed by shutters (see
fig. ). the source is preferably artificial, part of
matisse instrument, or could be a bright unresolved astronomical
target as well.
[kappa matrix] 
kappa matrix acquisition sequence in
the n-band, with alternatively just one out of four open
shutter.  
 
the photometric contribution  of the telescope  to
the interferometric beam can be expressed as following:
where  is a vector containing the contribution
of the telescope  to the photometric beams  (after chopping
correction, see section ),  is the
linear transformation matrix of the intensities in the photometric
channels into the interferometric channel (the so-called
"-matrix"), and ,  are the shift
offset and zoom coefficient to match the photometric beam  into the
interferometric beam.
we determine therefore the -matrix and the shift-and-zoom
coefficients by fitting the photometric beam shape and intensity to
the interferometric beam for each selected wavelength.
§.§.§ applying cosmetics
the first steps of the data reduction are:
eginenumerate
* subtracting the average (cold) dark  in each
frame,
* compensating of the space-variant gain in each frame by division
of each frame through the  (flat-field map),
* interpolating detector bad pixels in each frame with the  (bad pixel map),
* applying the distortion matrix to transform  to ,
the coordinates of the data,
* adjusting the photometric contribution in the interferometric
beam by applying the -matrix, shift, and zoom coefficients
the result of treating the three first effects is shown in
fig. . the two last corrections are being tested
right now on the mounted instrument in the nice laboratory.
the results of these processes are: a cleaned-up fringe pattern
, and cleaned-up photometric estimates
.
[distortion estimation] 
left: the raw image from the aquarius detector (7-13 m) contains four photometric channels,
the interferometric channel and 16 reference areas, showing bad pixels and detector channel
offsets.
right: the same image after the calibration step contains the photometric channels and the
interferometric channel only.
 
§.§ how to tackle the multiple-stage modulations in matisse
 
as described in petrov et al. (2016), matisse
includes a three-stage modulation process for the mitigation of the
sky background (as matisse works in the mid-infrared). these stages
are namely chopping, spatial modulation and temporal modulation, in
addition to beam commutation, which is used to clean up the phases out
of the instrumental effects.
§.§.§ chopping
chopping produces alternatively science and sky frames with a
switching frequency as fast as 1hz. the first step is to remove these
sky frames to the science frames, resulting in removing the bulk of
the background contribution (%):
§.§.§ spatial modulation
 
spatial modulation separates, in the fourier plane, the fringes energy
(“fringe peak”) from the flux energy (“photometric
peak”). therefore, a simple fourier processing along the  axis will cancel further
out the contribution of the background to the data.
correlated fluxes are computed just by fourier-transforming the clean
interferogram:
i^'(u, λ, t)     =     ft_x[i(x, λ, t)]
        =     f_00(u,λ,t) + ∑_i=1^4 ∑_j=i+1^4 [
    f_ij(u-f_ij, λ, t) · v_ij(λ) ·
    e^ıφ_ij(λ,t)]
where  is a spatial frequency,  is the fringe rate, as
explained below eq. ,  is the
target visibility,  is the phase of the target
plus piston, and  is a function of the
photometric contributions , involving fourier
transforms and correlations, representing the shape of the peaks. we
note that , and
that  represents the photometry peak.
the background residuals left after chopping contribute only to
 at first order, as the background does not
contain any coherent information. at the frequency of each fringe peak
, we have:
where the contribution of the residual background  is much smaller than
at the frequency 0 (as seen in fig.  on top and
bottom row).
§.§.§ temporal modulation
in addition to the spatial modulation, a temporal modulation is
introduced by piezoelectric actuators, changing the optical path
difference (opd)  by a fraction of the
wavelength between consecutive frames. let us consider that there are
 steps over an opd range of  during one modulation
cycle . the modulation is then ,  being the modulation step
number. 
on needs to consider the fringes “freezed” over the modulation time
 in order to consider 
constant. therefore, the modulation cycle must be done over one
atmosphere coherence time , or in conjunction with a
fringe tracker which freezes the fringes over a time
.
a de-modulation is applied to the previous fourier-transform,
baseline-by-baseline, and we integrate the fringe peak
 over one modulation cycle (the  steps of
modulation). we do so by multiplying it with a phasor containing the
counter-modulation:
i^”_ij(λ, t)    =   1/n_t∑_k=0^n_t
    i^'_ij(λ, t) × e^-2iπδ^ mod_ij(t)
    / λ
       =    f_ij(0,λ,t) · v_ij(λ) ·
    e^iφ_ij(λ,t) +
    δ b^ res_ij(λ,t)
the background residual is further reduced by the modulation, leading
to the final residual background :
the effect of demodulation can be seen in fig. ,
middle row. the combination of spatial modulation, temporal modulation
and chopping are the three ways selected in matisse to tackle the
dominance of the background. please note that neither the spatial nor
the temporal modulation can be applied to the photometries. therefore,
the rejection of the sky background in the photometric estimates rely
only on chopping, and will be of much lower quality.
[kappa matrix] 
left column: fourier
transform of the matisse fringe pattern.
right column: cut at one wavelength. top:
simulated fringe pattern after the chopping
correction. middle: same as before, but after the
temporal demodulation applied. bottom: same as first
one but on the real first fringes data shown in
fig. . the (de)modulation is not yet
operational on the instrument.
 
§.§ estimators
 
once the complex coherent flux  has been
computed, it is possible to compute the estimators, i.e. the raw
visibilities and phases of the object. these estimators are split
between incoherent estimators (speckle-like), that can be
computed without the knowledge of the optical path difference, and
coherent estimators that need an appropriate atmospheric opd
estimate, be it simply due to the turbulence or to higher-order
effects (longitudinal dispersion).
§.§.§ “incoherent” estimators
squared visibility
squared visibilities are computed as follows:
where  is the frequency around the considered baseline, and 
a bias estimated on  outside the range of frequencies where the
fringe peaks are present, and  and
 are the estimates of the photometric
fluxes transformed into the interferometric channel (see
eq. ).
in the case where there are no photometries recorded (like in
high-sens mode without a photometric acquisition sequence), the
squared visibilities are simply not computed. instead, the user should
use the correlated fluxes, i.e. the upper part of
eq. :
closure phase 
the bispectrum is calculated by:
where , , and  are the frequencies of the baselines
involved in the closure relation. an example matisse bispectrum can be
seen in fig. . out of the 5 peaks that can be
seen, just 4 contain useful information from the 4 closure phases
available at 4 telescopes (the middle-left peak is a spurious peak
coming from the contamination of the central photometric peak).
this average bispectrum contains an additive noise bias terms plus a
multiplicative one, because of the all-in-one combination of the
interferograms.  these biases need to be subtracted in order to get
closure phases without systematic errors, following specific
recipes.
[kappa matrix] 
example bispectrum values computed
on simulated matisse data. top graph: real part, and
bottom graph: imaginary part. the middle-left peak is
spurious. 
 
§.§.§ “coherent” estimators
coherent estimators need an appropriate opd estimate. we describe here
briefly what we envision to include in . the complex
coherent flux is provided by the equation .
the phase term  depends on the variations of
the atmospheric properties (temperature, pressure), producing an
achromatic variation of opd (but not phase), and it depends also on
the refractive index  of air, which is chromatic and
dependent of its water vapor composition. it can be expressed as:
the different terms are the following:
eginitemize 
* : achromatic part of
the atmospheric opd, 
* , chromatic term with  wavelength-dependent but
roughly static , and  wavelength
independent, but with strong variations in
time  
* : the object phase, which can be decomposed in a
taylor series containing the differential phase .  
achromatic optical path difference estimates:
 
matisse will compute the achromatic opd using a vega-like
algorithm: a 2d-fourier
transform (ft) is computed, to take profit of the multi-axial beam
combination of matisse. the fringe peak in the power spectrum appears
as an offset peak, whose offset is proportional to the opd. the great
advantage of this method is that the peak is concentrated onto a small
location of the 2d map, whereas the noise is spread everywhere, hence
contributing to a smaller fraction of the peak noise. in addition,
there is no ambiguity at opd 0, contrary to a midi-like estimate.
this 2d-ft can be computed in two steps, first in the spatial
direction and second in the spectral direction, allowing us to
counteract the opd modulation pattern before elevating the fourier
transform to its square, and hence increasing tremendously the snr of
the peak detection. this is also the way the fringe pattern will be
detected in real time with the instrument.
another option implemented for opd determination is a fit to the
complex coherent flux phase, in the very same way as it is done for
amber .
the computed atmospheric opd contains then the two terms: 
.
chromatic opd estimates:
eso provides information through the ambient conditions monitor that
will be sufficient to correct the data from the chromatic dry and wet
air dispersion, down to accuracies of 3 degrees in k band and down to
10 degrees in n-band.
the static water vapor term  will be computed using the
pressure , temperature  (in the tunnels), and relative humidity
of the ambient air . we add to these the partial pressure of
co, which can be hard-coded to an average value at paranal. the
fraction of humidity is converted into partial pressure of water vapor
.  the -dependent shape of the
chromatic phase  is then be determined based on computed
optical index of air  as a function of wavelength .  the next step is to compute phases, and therefore we
also use the information of the delay lines position to compute the
difference of delay for each baseline: if  is the static optical
path introduced by the delay line , and  the dynamic path,
 is the total path of air introduced by each delay
line. per baseline , the path to use for the chromatic opd is
therefore . the chromatic
phase is then computed by , with  the computed index of air,
and  the wavelength of interest. 
the water vapor phase offset, time-variable, , will be obtained by averaging the phase term in
the wavelength-direction after subtraction of the atmospheric
opd. as a consequence, it also removes the object-related phase
offset . the result is therefore .
all these calculations yield ,
, and .
differential phase: 
after that step, the computed phase is transformed into a differential
phase the standard way . we recall it briefly here. first, we multiply
the fourier transform of the correlated interferograms by the counter
opd phasor. this yields the opd-free complex coherent flux:
cf_ij(λ, t)     =     i^”_ij(λ, t) ×
    e^-2iπ ( [ δ_ij^ atm(t) / λ
    + φ_ij^(1)] + [ δ_ij^ atm(t)·
    b(t)+φ_ij^(0)] + a(λ) ) 
        =     f_ij(0,λ,t) · v_ij(λ) · 
    e^i φ_ij^ diff(λ)
averaging this opd-free complex coherent flux over time yields the
following products:
eginitemize
* : correlated flux degraded
by the not corrected beam overlap
* : differential phase, with any
wavelength-linear phase term set to zero.
coherent visibility: 
finally, it is possible to continue the processing to lead to a linear
visibility estimate. for that, we divide the correlated flux by the
photometric factor. this is the last optional step, yielding the
linear visibility estimate:
in the case where there are no photometries recorded (like in
high-sens mode), this term is not computed, as for the squared
visibilities.
§.§ data calibration
 
to calibrate the data, we apply the same recipes as in
amber, i.e.:
eginitemize
* we start with searching calibrator stars diameters in published catalogs,
* we divide the calibrators visibilities by their expected visibilities and store the transfer function result in new files,
* we interpolate the transfer function to the time of the science observations with a gaussian-weighted average (typical fwhm 1hr),
* we divide the science visibilities with the interpolated
transfer function and store the result as calibrated science-grade
data files.
uses the eso-developed  interface to run all the steps, and the
calibration part contains a display of the result, allowing the user
to select the relevant calibration stars (see
fig. )
[kappa matrix] 
example displays of
the  workflow: left: transfer function
plot and selection, middle: visibility comparison plot
between observed (blue) and reconstructed (red)
visibilities, coming from the image reconstruction process,
right: image display showing the reconstructed image
and the prior image.
 
§.§ image reconstruction
 
the last step of  is the image reconstruction. matisse
will use the irbis algorithm, which was specially developed for
it. the content of irbis is extensively described in another paper of
this conference. the  software
displays the results of the reconstruction through a python interface,
shown in fig. .
§ conclusion
we presented the matisse data reduction software  as it
has been implemented for the matisse instrument. 
produces calibrated dispersed visibilities, closure phases and
differential phases from the beginning, and also includes the irbis
algorithm for image reconstruction. matisse is presently undergoing
laboratory tests to verify that it meets all the necessary
requirements to reach its science goals. the tests of 
is a significant part of these tests.
we are grateful to eso, cnrs/insu, and the max-planck society for
continuous support in the matisse project.
spiebib   
/edocument/ 
