{
  "arxiv_id": "2410.17961",
  "found": true,
  "title": "Closed-form merging of parameter-efficient modules for Federated Continual Learning",
  "authors": [
    "Riccardo Salami",
    "Pietro Buzzega",
    "Matteo Mosconi",
    "Jacopo Bonato",
    "Luigi Sabetta",
    "Simone Calderara"
  ],
  "first_author": "Riccardo Salami",
  "summary": "Model merging has emerged as a crucial technique in Deep Learning, enabling the integration of multiple models into a unified system while preserving perfor-mance and scalability. In this respect, the compositional properties of low-rank adaptation techniques (e.g., LoRA) have proven beneficial, as simple averaging LoRA modules yields a single model that mostly integrates the capabilities of all individual modules. Building on LoRA, we take a step further by imposing that the merged model matches the responses of all learned modules. Solving this objective in closed form yields an indeterminate system with A and B as unknown variables, indicating the existence of infinitely many closed-form solutions. To address this challenge, we introduce LoRM, an alternating optimization strategy that trains one LoRA matrix at a time. This allows solving for each unknown variable individually, thus finding a unique solution. We apply our proposed methodology to Federated Class-Incremental Learning (FCIL), ensuring alignment of model responses both between clients and across tasks. Our method demonstrates state-of-the-art performance across a range of FCIL scenarios. The code to reproduce our experiments is available at github.com/aimagelab/fed-mammoth.",
  "primary_category": "cs.LG",
  "categories": [
    "cs.LG",
    "cs.AI"
  ],
  "published": "2024-10-23T15:30:13+00:00",
  "updated": "2025-03-08T17:15:08+00:00",
  "doi": null,
  "journal_ref": null,
  "comment": null,
  "pdf_url": "https://arxiv.org/pdf/2410.17961v2",
  "entry_id": "http://arxiv.org/abs/2410.17961v2"
}